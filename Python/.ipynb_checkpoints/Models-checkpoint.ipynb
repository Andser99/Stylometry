{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c6f5e5",
   "metadata": {},
   "source": [
    "# Stylometry - model training\n",
    "\n",
    "### Used classifiers\n",
    " - Decision Tree\n",
    " - kNN (NYI)\n",
    " - SVM (NYI)\n",
    " \n",
    " \n",
    " - ? Logistic Regression (NYI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255418f1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f23b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn import preprocessing\n",
    "from dateutil import parser\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, chi2, f_regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import tree, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d9e01e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e6734",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34e2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df_to_scale, ignored_cols):\n",
    "    cols_to_scale = df_to_scale.drop(ignored_cols , axis=1).columns\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df_to_scale[cols_to_scale] = min_max_scaler.fit_transform(df_to_scale[cols_to_scale])\n",
    "    df.info()\n",
    "    return df_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0fc4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(real, predicted):\n",
    "    print(\"Evaluation: \")\n",
    "    countGood = 0\n",
    "    total = len(real)\n",
    "    falsePos = 0\n",
    "    falseNeg = 0\n",
    "    truePos = 0\n",
    "    trueNeg = 0\n",
    "    if total != len(predicted):\n",
    "        print(\"Non-matching sample lengths\")\n",
    "        return None\n",
    "    for i in range(0, total):\n",
    "        countGood += 1 if real[i] == predicted[i] else 0\n",
    "\n",
    "    # accuracy = str(countGood / total)\n",
    "    # precision = str(truePos / (truePos + falsePos))\n",
    "    # recall = str(truePos / (truePos + falseNeg))\n",
    "    \n",
    "    print(\"accuracy \" + str(countGood / total))\n",
    "    return countGood / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8159def",
   "metadata": {},
   "source": [
    "## Data import\n",
    "\\+calculate positional error occurence per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb8b325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137400 entries, 0 to 137399\n",
      "Columns: 2304 entries, Author to Downerror_pertokens\n",
      "dtypes: float64(2267), int64(36), object(1)\n",
      "memory usage: 2.4+ GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>UppercaseLetter</th>\n",
       "      <th>UppercaseLetter_pertokens</th>\n",
       "      <th>LowercaseLetter</th>\n",
       "      <th>LowercaseLetter_pertokens</th>\n",
       "      <th>TitlecaseLetter</th>\n",
       "      <th>TitlecaseLetter_pertokens</th>\n",
       "      <th>ModifierLetter</th>\n",
       "      <th>ModifierLetter_pertokens</th>\n",
       "      <th>OtherLetter</th>\n",
       "      <th>...</th>\n",
       "      <th>swap_ _m</th>\n",
       "      <th>swap_ _CO</th>\n",
       "      <th>swap_ _.</th>\n",
       "      <th>swap_ _/</th>\n",
       "      <th>swap_ _</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Toperror_pertokens</th>\n",
       "      <th>Lefterror_pertokens</th>\n",
       "      <th>Righterror_pertokens</th>\n",
       "      <th>Downerror_pertokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>1.226</td>\n",
       "      <td>60</td>\n",
       "      <td>1.935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0.286</td>\n",
       "      <td>125</td>\n",
       "      <td>2.976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>0.150</td>\n",
       "      <td>582</td>\n",
       "      <td>3.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.005988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Author  UppercaseLetter  UppercaseLetter_pertokens  LowercaseLetter  \\\n",
       "0      13               38                      1.226               60   \n",
       "1      13               12                      0.286              125   \n",
       "2      13               25                      0.150              582   \n",
       "\n",
       "   LowercaseLetter_pertokens  TitlecaseLetter  TitlecaseLetter_pertokens  \\\n",
       "0                      1.935                0                        0.0   \n",
       "1                      2.976                0                        0.0   \n",
       "2                      3.485                0                        0.0   \n",
       "\n",
       "   ModifierLetter  ModifierLetter_pertokens  OtherLetter  ...  swap_ _m  \\\n",
       "0               0                       0.0            0  ...       0.0   \n",
       "1               0                       0.0            0  ...       0.0   \n",
       "2               0                       0.0            0  ...       0.0   \n",
       "\n",
       "   swap_ _CO  swap_ _.  swap_ _/  swap_ _   Tokens  Toperror_pertokens  \\\n",
       "0        0.0       0.0       0.0       0.0      31                 0.0   \n",
       "1        0.0       0.0       0.0       0.0      42                 0.0   \n",
       "2        0.0       0.0       0.0       0.0     167                 0.0   \n",
       "\n",
       "   Lefterror_pertokens  Righterror_pertokens  Downerror_pertokens  \n",
       "0             0.064516              0.000000             0.000000  \n",
       "1             0.023810              0.000000             0.000000  \n",
       "2             0.023952              0.035928             0.005988  \n",
       "\n",
       "[3 rows x 2304 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('allauthors_100articles_cut.csv', sep=',')\n",
    "df['Toperror_pertokens'] = df['Toperror'] / df['Tokens']\n",
    "df['Lefterror_pertokens'] = df['Lefterror'] / df['Tokens']\n",
    "df['Righterror_pertokens'] = df['Righterror'] / df['Tokens']\n",
    "df['Downerror_pertokens'] = df['Downerror'] / df['Tokens']\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05cdee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"∞\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b418a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137400 entries, 0 to 137399\n",
      "Columns: 2304 entries, Author to Downerror_pertokens\n",
      "dtypes: float64(2302), int64(2)\n",
      "memory usage: 2.4 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>UppercaseLetter</th>\n",
       "      <th>UppercaseLetter_pertokens</th>\n",
       "      <th>LowercaseLetter</th>\n",
       "      <th>LowercaseLetter_pertokens</th>\n",
       "      <th>TitlecaseLetter</th>\n",
       "      <th>TitlecaseLetter_pertokens</th>\n",
       "      <th>ModifierLetter</th>\n",
       "      <th>ModifierLetter_pertokens</th>\n",
       "      <th>OtherLetter</th>\n",
       "      <th>...</th>\n",
       "      <th>swap_ _m</th>\n",
       "      <th>swap_ _CO</th>\n",
       "      <th>swap_ _.</th>\n",
       "      <th>swap_ _/</th>\n",
       "      <th>swap_ _</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Toperror_pertokens</th>\n",
       "      <th>Lefterror_pertokens</th>\n",
       "      <th>Righterror_pertokens</th>\n",
       "      <th>Downerror_pertokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>0.029902</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.004166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.004321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137395</th>\n",
       "      <td>19319</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137396</th>\n",
       "      <td>19319</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137397</th>\n",
       "      <td>19319</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137398</th>\n",
       "      <td>19319</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137399</th>\n",
       "      <td>19319</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137400 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author  UppercaseLetter  UppercaseLetter_pertokens  LowercaseLetter  \\\n",
       "0           13         0.007528                   0.029902         0.000286   \n",
       "1           13         0.002377                   0.006976         0.000595   \n",
       "2           13         0.004952                   0.003659         0.002770   \n",
       "3           13         0.012678                   0.004244         0.005654   \n",
       "4           13         0.003170                   0.002415         0.002808   \n",
       "...        ...              ...                        ...              ...   \n",
       "137395   19319         0.003170                   0.004634         0.001575   \n",
       "137396   19319         0.001585                   0.006512         0.000485   \n",
       "137397   19319         0.002179                   0.008122         0.000476   \n",
       "137398   19319         0.002971                   0.014073         0.000314   \n",
       "137399   19319         0.001585                   0.002317         0.001518   \n",
       "\n",
       "        LowercaseLetter_pertokens  TitlecaseLetter  TitlecaseLetter_pertokens  \\\n",
       "0                        0.004478              0.0                        0.0   \n",
       "1                        0.006888              0.0                        0.0   \n",
       "2                        0.008066              0.0                        0.0   \n",
       "3                        0.007471              0.0                        0.0   \n",
       "4                        0.008482              0.0                        0.0   \n",
       "...                           ...              ...                        ...   \n",
       "137395                   0.009119              0.0                        0.0   \n",
       "137396                   0.007869              0.0                        0.0   \n",
       "137397                   0.007013              0.0                        0.0   \n",
       "137398                   0.005874              0.0                        0.0   \n",
       "137399                   0.008790              0.0                        0.0   \n",
       "\n",
       "        ModifierLetter  ModifierLetter_pertokens  OtherLetter  ...  swap_ _m  \\\n",
       "0                  0.0                       0.0          0.0  ...       0.0   \n",
       "1                  0.0                       0.0          0.0  ...       0.0   \n",
       "2                  0.0                       0.0          0.0  ...       0.0   \n",
       "3                  0.0                       0.0          0.0  ...       0.0   \n",
       "4                  0.0                       0.0          0.0  ...       0.0   \n",
       "...                ...                       ...          ...  ...       ...   \n",
       "137395             0.0                       0.0          0.0  ...       0.0   \n",
       "137396             0.0                       0.0          0.0  ...       0.0   \n",
       "137397             0.0                       0.0          0.0  ...       0.0   \n",
       "137398             0.0                       0.0          0.0  ...       0.0   \n",
       "137399             0.0                       0.0          0.0  ...       0.0   \n",
       "\n",
       "        swap_ _CO  swap_ _.  swap_ _/  swap_ _   Tokens  Toperror_pertokens  \\\n",
       "0             0.0       0.0       0.0       0.0      31            0.000000   \n",
       "1             0.0       0.0       0.0       0.0      42            0.000000   \n",
       "2             0.0       0.0       0.0       0.0     167            0.000000   \n",
       "3             0.0       0.0       0.0       0.0     368            0.000000   \n",
       "4             0.0       0.0       0.0       0.0     161            0.008696   \n",
       "...           ...       ...       ...       ...     ...                 ...   \n",
       "137395        0.0       0.0       0.0       0.0      84            0.000000   \n",
       "137396        0.0       0.0       0.0       0.0      30            0.000000   \n",
       "137397        0.0       0.0       0.0       0.0      33            0.000000   \n",
       "137398        0.0       0.0       0.0       0.0      26            0.000000   \n",
       "137399        0.0       0.0       0.0       0.0      84            0.000000   \n",
       "\n",
       "        Lefterror_pertokens  Righterror_pertokens  Downerror_pertokens  \n",
       "0                  0.032258              0.000000             0.000000  \n",
       "1                  0.011905              0.000000             0.000000  \n",
       "2                  0.011976              0.017964             0.004166  \n",
       "3                  0.000000              0.000000             0.000000  \n",
       "4                  0.015528              0.012422             0.004321  \n",
       "...                     ...                   ...                  ...  \n",
       "137395             0.000000              0.000000             0.000000  \n",
       "137396             0.000000              0.016667             0.000000  \n",
       "137397             0.015152              0.000000             0.000000  \n",
       "137398             0.000000              0.019231             0.000000  \n",
       "137399             0.000000              0.005952             0.000000  \n",
       "\n",
       "[137400 rows x 2304 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols_to_scale = df.drop([\"Author\", \"Tokens\"] , axis=1).columns\n",
    "# df_all = df\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "# df_all[cols_to_scale] = min_max_scaler.fit_transform(df_all[cols_to_scale])\n",
    "df_all = scale(df, [\"Author\", \"Tokens\"])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4137bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all['Author'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f5b0a",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "df_all - contains all feature columns and author id\n",
    "\n",
    "df_positional - contains positional errors, token count, misspell ratio and author id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390a28c",
   "metadata": {},
   "source": [
    "non_empty_cols - all columns with non-zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761b6cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_cols = df_all.columns\n",
    "to_add_cols = [  'Author',\n",
    "                 'CurrencySymbol_pertokens',\n",
    "                 'ConnectorPunctuation_pertokens',\n",
    "                 'Downerror_pertokens',\n",
    "                 'DecimalDigitNumber_pertokens',\n",
    "                 'FinalQuotePunctuation_pertokens',\n",
    "                 'InitialQuotePunctuation_pertokens',\n",
    "                 'LowercaseLetter_pertokens',\n",
    "                 'Lefterror_pertokens',\n",
    "                 'MathSymbol_pertokens',\n",
    "                 'Misspellratio',\n",
    "                 'OtherLetter_pertokens',\n",
    "                 'OtherNotAssigned_pertokens',\n",
    "                 'Righterror_pertokens',\n",
    "                 'SpaceSeparator_pertokens',\n",
    "                 'Toperror_pertokens',\n",
    "                 'UppercaseLetter_pertokens']\n",
    "\n",
    "\n",
    "# non-empty PoS tag columns\n",
    "prefixes = ['pos_',\n",
    "            'swap_']\n",
    "for col in all_cols:\n",
    "    if (not((df_all[col] == 0).all()) and any(col.startswith(x) for x in prefixes)):\n",
    "        to_add_cols.append(col)\n",
    "df_positional = df_all[to_add_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7a22c",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "removing NaN and inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58942270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 137183 entries, 0 to 137399\n",
      "Columns: 2239 entries, Author to swap_ _ \n",
      "dtypes: float64(2239)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "df_positional.dropna()\n",
    "indices_to_keep = ~df_positional.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "df_positional = df_positional[indices_to_keep].astype(np.float64)\n",
    "df_positional.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71aecf",
   "metadata": {},
   "source": [
    "## OPTIONAL \n",
    "+ used to reduce the number of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "452454d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_authors = df_all[\"Author\"].unique()\n",
    "split_authors = all_authors[0:len(all_authors)//1]\n",
    "df_positional = df_positional[(df_positional[\"Author\"] >= split_authors[0]) \n",
    "                                & (df_positional[\"Author\"] <= split_authors[-1])]\n",
    "\n",
    "len(df_positional[\"Author\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e24ca",
   "metadata": {},
   "source": [
    "# Split to train/test\n",
    "!TODO, only taking a random sample and testing it on itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a2ccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82309 entries, 117280 to 22064\n",
      "Columns: 2239 entries, Author to swap_ _ \n",
      "dtypes: float64(2239)\n",
      "memory usage: 1.4 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54231 entries, 2 to 137398\n",
      "Columns: 2239 entries, Author to swap_ _ \n",
      "dtypes: float64(2239)\n",
      "memory usage: 926.8 MB\n",
      "137183\n"
     ]
    }
   ],
   "source": [
    "data_count = len(df_positional)\n",
    "percentage_to_train = 0.60\n",
    "df_train = df_positional.sample(int(data_count*(percentage_to_train)))\n",
    "df_test = pd.concat([df_train, df_positional]).drop_duplicates(keep=False)\n",
    "# df_test = df_positional[int(data_count*2/3):]\n",
    "df_train.info()\n",
    "df_test.info()\n",
    "print(data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d0e56",
   "metadata": {},
   "source": [
    "### Split training into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1b5d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82309"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.drop('Author', axis=1)\n",
    "y = df_train[\"Author\"]\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d3487",
   "metadata": {},
   "source": [
    "# Model fitting\n",
    "### Decision Tree Classifier\n",
    "Create a decision tree classifier and get predictions on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05305ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(random_state=3)\n",
    "dt = dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd6e152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_authors = df_train[\"Author\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2677d4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3660a773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', random_state=0)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9670f",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a78e8107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 703. MiB for an array with shape (82309, 2238) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_15188/3765938151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mc:\\users\\andrej\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 703. MiB for an array with shape (82309, 2238) and data type float32"
     ]
    }
   ],
   "source": [
    "forest=RandomForestClassifier(n_estimators=100, max_depth=45)\n",
    "forest.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091642b",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Create features and labels from testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4e95d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = df_test.drop('Author', axis=1)\n",
    "Y_test = df_test['Author'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7ce84",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ff52201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: \n",
      "accuracy 0.046652283749147164\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "predictions_dt = dt.predict(X_test)\n",
    "dt_acc = evaluate(Y_test, predictions_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a266786",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aa8cee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: \n",
      "accuracy 0.03355704697986577\n"
     ]
    }
   ],
   "source": [
    "predictions_logreg = model.predict(X_test)\n",
    "logreg_acc = evaluate(Y_test, predictions_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ac6f1",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e5f69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: \n",
      "accuracy 0.08526488539765079\n"
     ]
    }
   ],
   "source": [
    "predictions_forest = forest.predict(X_test)\n",
    "forest_acc = evaluate(Y_test, predictions_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d77e28d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n",
      "0.6209917971662938\n",
      "Logreg\n",
      "0.03355704697986577\n",
      "Forest\n",
      "0.42449664429530204\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision tree\")\n",
    "print(dt_acc)\n",
    "print(\"Logreg\")\n",
    "print(logreg_acc)\n",
    "print(\"Forest\")\n",
    "print(forest_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99df402",
   "metadata": {},
   "source": [
    "# Other -------- UNRELATED -------\n",
    "under construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e390ced9",
   "metadata": {},
   "source": [
    "## Automatic feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adc70e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_features(df, k=5):\n",
    "#     df_new = df.drop([\"Author\"], axis=1)\n",
    "#     indicators_indexed = []\n",
    "#     for x in df['Author']:\n",
    "#         indicators_indexed.append(x)\n",
    "# #     print(len(indicators_indexed))\n",
    "#     # print(df_normal)\n",
    "#     np.random.seed(1)\n",
    "#     selector = SelectKBest(chi2, k=k)\n",
    "# #     selector = SelectKBest(mutual_info_regression, k=k)\n",
    "#     k_best_features = selector.fit_transform(df_new.values, indicators_indexed)\n",
    "#     print(selector.get_support(1))\n",
    "#     return (k_best_features, selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cfffeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat, mask = select_features(df_train, 6)\n",
    "\n",
    "# new_features = df_train.drop([\"Author\"], axis=1).columns[mask]\n",
    "# new_features\n",
    "# # print(ind)\n",
    "# df_positional = df_all[new_features]\n",
    "# df_positional[\"Author\"] = df_all[\"Author\"]\n",
    "# df_positional.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
